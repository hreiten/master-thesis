{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# reset variables\n",
    "%reset -f\n",
    "\n",
    "import os, sys\n",
    "\n",
    "ROOT_PATH = os.path.abspath(\".\").split(\"src\")[0]\n",
    "\n",
    "module_path = os.path.abspath(os.path.join(ROOT_PATH+\"/src/utils/\"))\n",
    "module_path_venv = os.path.abspath(os.path.join(ROOT_PATH+\"/venv/lib/python3.6/site-packages/\"))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    sys.path.insert(0, module_path_venv)\n",
    "\n",
    "import pickle\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "\n",
    "from matplotlib import rc\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from functions import MAE, RMSE, split_dataset\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import functions as f\n",
    "import dl_functions as dlf\n",
    "\n",
    "SEED=100\n",
    "np.random.seed(SEED)\n",
    "tf.set_random_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure matplotlib params and plotting\n",
    "sns.set()\n",
    "sns.set_context('paper')\n",
    "sns.set_style('whitegrid', {'axes.grid': True, 'grid.linestyle': '--'})\n",
    "\n",
    "rc('figure', figsize=(12,6), dpi=300)\n",
    "rc('xtick', labelsize=12)\n",
    "rc('ytick', labelsize=12)\n",
    "rc('axes', labelsize=13, titlesize=14)\n",
    "rc('legend', fontsize=14, handlelength=2)\n",
    "rc('font', family='serif')\n",
    "rc('text', color=\"#000000\")\n",
    "rc('xtick', color=\"#000000\")\n",
    "rc('ytick', color=\"#000000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data and metadata\n",
    "df_train, df_valid, df_test, df_anomaly = f.load_data(return_anomaly=True)\n",
    "stats_set, ts, ts_train, ts_valid, ts_test, ts_anomaly = f.load_metadata(return_anomaly=True)\n",
    "\n",
    "# split datasets into features and targets\n",
    "x_train, y_train = f.split_dataset(df_train.values, delay=1)\n",
    "x_valid, y_valid = f.split_dataset(df_valid.values, delay=1)\n",
    "x_test, y_test = f.split_dataset(df_test.values, delay=1)\n",
    "x_anomaly, y_anomaly = f.split_dataset(df_anomaly.values, delay=1)\n",
    "\n",
    "# metadata\n",
    "target_tags = df_train.columns.values[:3]\n",
    "feature_tags = df_train.columns.values[3:]\n",
    "target_stds = stats_set.loc[target_tags,\"Std\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/shomeb/t/thomklei/master_thesis/venv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/shomeb/t/thomklei/master_thesis/venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/shomeb/t/thomklei/master_thesis/venv/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "x_pred = x_anomaly\n",
    "y_pred = y_anomaly\n",
    "\n",
    "model = dlf.load_keras_model(ROOT_PATH+\"models/lstm_128/50/\")\n",
    "\n",
    "# predict with the model\n",
    "predicted_train, std_preds, pred_dict = dlf.predict_with_model(model, x_valid, y_valid, n_predictions=10)\n",
    "y_hat, std_preds, pred_dict = dlf.predict_with_model(model, x_pred, y_pred, n_predictions=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create residual distribution\n",
    "def create_residual_distribution(signal, plot = True):\n",
    "    N = 5\n",
    "\n",
    "    res_dist = predicted_train[:,signal][:MIN_NUMBER_OF_RESIDUALS] - y_train[:,signal][:MIN_NUMBER_OF_RESIDUALS]\n",
    "    exp_smoothed = np.ravel(\n",
    "        pd.DataFrame(\n",
    "            res_dist\n",
    "        ).ewm(alpha = 0.6).mean().values\n",
    "    )\n",
    "    rolling_smoothed = pd.Series(res_dist).rolling(window=N).mean().iloc[N-1:].values\n",
    "\n",
    "    if plot:\n",
    "        positions = [131, 132, 133]\n",
    "        fig = plt.figure()\n",
    "        fig.suptitle('Signal: {}'.format(signal), fontsize=16)\n",
    "        axs = [fig.add_subplot(i) for i in positions]\n",
    "        axs[0].hist(res_dist, label=\"Residual dist.\")\n",
    "        axs[1].hist(exp_smoothed, label=\"Exp. smoothed\")\n",
    "        axs[2].hist(rolling_smoothed, label=\"Rolling. smoothed\")\n",
    "        [ax.legend(frameon=True) for ax in axs]\n",
    "        \n",
    "    return rolling_smoothed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_NUMBER_OF_RESIDUALS = 900\n",
    "\n",
    "res = [create_residual_distribution(\n",
    "            signal = i,\n",
    "            plot = True\n",
    "        ) for i in range(0,3)\n",
    "      ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ranges(x):\n",
    "    ranges = list()\n",
    "    index = x[0]\n",
    "    for i, value in enumerate(x):\n",
    "        if (i == len(x) - 1):\n",
    "            break\n",
    "        if (value != (x[i + 1] - 1)):\n",
    "            if (abs(index - x[i])) < 1:\n",
    "                index = x[i+1]\n",
    "            else:\n",
    "                ranges.append((index, x[i]))\n",
    "                index = x[i+1]\n",
    "            \n",
    "    return ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START = 5000\n",
    "END = 40000\n",
    "tau = 5\n",
    "DELTA = 100\n",
    "x = ts_anomaly[START:END]\n",
    "\n",
    "a_rs = [get_ranges(np.where(abs(y_pred[:, signal][START:END]) > tau)[0]) for signal in range(0,3)]\n",
    "a_rs = list(itertools.chain(*a_rs))\n",
    "a_rs = sorted(a_rs)\n",
    "\n",
    "a_rs_d = [(x[a_r[0]], x[a_r[1]]) for a_r in a_rs]\n",
    "\n",
    "\n",
    "positions = [111]\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.plot(x[::DELTA], y_pred[:,0][START:END][::DELTA], label=\"FT\", c = \"darkblue\")\n",
    "ax.plot(x[::DELTA], y_pred[:,1][START:END][::DELTA], label=\"TT\", c = \"darkred\")\n",
    "ax.plot(x[::DELTA], y_pred[:,2][START:END][::DELTA], label=\"PT\", c = \"darkgreen\")\n",
    "[ax.axvspan(a[0], a[1], alpha=0.3, color='grey', lw = 4) for a in a_rs_d]\n",
    "ax.axhline(y=tau,lw=1, linestyle='--')\n",
    "ax.axhline(y=-tau,lw=1, linestyle='--')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilistic anomaly detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot results\n",
    "def plot_probabilistic_anomalies(anomaly_likelihoods, signal = 0, verbose = True):\n",
    "    UPPER_ANOMALY_THRESHOLD = 0.99 if not log_likelihood else 0.6\n",
    "\n",
    "    x = ts_anomaly[START:END]\n",
    "    positions = [411, 412]\n",
    "    \n",
    "    fig = plt.figure(figsize=(16, 15))\n",
    "    \n",
    "    axs = [fig.add_subplot(i) for i in positions]\n",
    "\n",
    "    axs[0].plot(\n",
    "        x[::2], \n",
    "        anomaly_likelihoods[START:END][::2],\n",
    "        c='darkblue', \n",
    "        lw=0,\n",
    "        marker='o',\n",
    "        ms=1,\n",
    "        label = \"\\$Log Anomaly Likelihood\\$\"\n",
    "    )\n",
    "    \n",
    "    axs[0].axhline(\n",
    "        y=UPPER_ANOMALY_THRESHOLD, \n",
    "        c='darkred', \n",
    "        linestyle='--'\n",
    "    )\n",
    "    \n",
    "    axs[0].set_ylim(0, 1.05)\n",
    "    [axs[0].axvspan(a[0], a[1], alpha=0.2, color='grey', lw = 3) for a in a_rs_d]\n",
    "\n",
    "\n",
    "    axs[1].plot(\n",
    "        x[::DELTA],\n",
    "        y_pred[:,signal][START:END][::DELTA], \n",
    "        c=\"darkgreen\", \n",
    "        label = \"Actual\"\n",
    "    )\n",
    "    axs[1].plot(\n",
    "        x[::DELTA], \n",
    "        y_hat[:, signal][START:END][::DELTA], \n",
    "        c=\"darkblue\", \n",
    "        label = \"Predicted\"\n",
    "    )\n",
    "    axs[1].set_ylim(-10, 10)\n",
    "\n",
    "    red_marks = x[np.where((anomaly_likelihoods[START:END] > UPPER_ANOMALY_THRESHOLD) == True)[0]]\n",
    "    \n",
    "    [axs[1].axvspan(red_marks[i], red_marks[i], alpha=0.4, color='pink', lw=3) for i in range(0, len(red_marks) - 1)]\n",
    "\n",
    "    [ax.legend(frameon=True) for ax in axs]\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        print(\\\n",
    "            'Total number of points in anomaly range: {num_points_in_anomaly_range} \\n Total number of flagged anomalies:  {num_flagged} \\n In range anomalies: {in_range_anomalies} \\n Out of range anomalies: {out_of_range_anomalies}'.format(\n",
    "                num_points_in_anomaly_range = num_points_in_anomaly_range,\n",
    "                num_flagged = np.sum(predicted_anomalies),\n",
    "                in_range_anomalies = np.sum(in_range_anomalies),\n",
    "                out_of_range_anomalies = np.sum(predicted_anomalies) - np.sum(in_range_anomalies)\n",
    "        ))\n",
    "        \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = 0\n",
    "plot_probabilistic_anomalies(anomaly_likelihoods = anomaly_likelihoods[signal], signal = signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tailProbability(x, mu, sigma):\n",
    "    z = (x - mu) / sigma\n",
    "    return 1.0 - 0.5 * math.erfc(z / np.sqrt(2))\n",
    "\n",
    "def calculate_anomaly_score(residuals):\n",
    "     return pd.DataFrame(\n",
    "        residuals, \n",
    "        columns = ['res']\n",
    "    ).ewm(alpha = 0.2).mean()['res'].values[-1]\n",
    "    \n",
    "\n",
    "def calculate_anomaly_likelihood(\n",
    "    residuals,\n",
    "    y, \n",
    "    y_hat, \n",
    "    mu,\n",
    "    sigma,\n",
    "    model = model,\n",
    "):\n",
    "    anomaly_score = calculate_anomaly_score(residuals = residuals)\n",
    "    anomaly_likelihood = tailProbability(anomaly_score, mu, sigma)\n",
    "    \n",
    "    if log_likelihood:\n",
    "        return np.log(1.0000000001 - 2 * abs(0.5 - anomaly_likelihood)) / np.log(1.0 - 0.9999999999)\n",
    "    else:\n",
    "        return abs(0.5 - anomaly_likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "log_likelihood = True\n",
    "NUM_AVERAGED_ANOMALY_SCORES = 15\n",
    "\n",
    "residuals = np.zeros(len(y_hat))\n",
    "anomaly_likelihoods = [np.zeros(len(y_hat)) for i in range (0, 3)]\n",
    "\n",
    "def run(plot = True):\n",
    "    for signal in range(0, 3):\n",
    "        res_dist = create_residual_distribution(signal = signal, plot = False)\n",
    "        (mu, sigma) = getattr(stats, 'norm').fit(res_dist)\n",
    "        \n",
    "        for index in range(START, END):    \n",
    "            residual = y_hat[:,signal][index] - y_pred[:,signal][index]\n",
    "            residuals[index] = residual\n",
    "            \n",
    "            anomaly_likelihoods[signal][index] = calculate_anomaly_likelihood(\n",
    "                residuals = residuals[(index - NUM_AVERAGED_ANOMALY_SCORES): (index + 1)],\n",
    "                y = y_pred,\n",
    "                y_hat = y_hat,\n",
    "                mu = mu,\n",
    "                sigma = sigma\n",
    "            )\n",
    "        \n",
    "        if plot:\n",
    "            plot_probabilistic_anomalies(signal = signal, anomaly_likelihoods = anomaly_likelihoods[signal])\n",
    "        \n",
    "    return anomaly_likelihoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_likelihoods = run(plot = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PI Anomaly Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def pi_anomaly_detection(verbose = True):\n",
    "    for signal in range(0,3):\n",
    "        alpha = 4\n",
    "        \n",
    "        x = ts_anomaly[START:END]\n",
    "        anomaly_range_start = np.where(x == anomaly_range[0])[0][0] + START\n",
    "        anomaly_range_end = np.where(x == anomaly_range[-1])[0][0] + START\n",
    "        positions = [411, 412]\n",
    "    \n",
    "        \n",
    "        lower_pi = y_hat[:, signal] - alpha * std_preds[:, signal]\n",
    "        upper_pi = y_hat[:, signal] + alpha * std_preds[:, signal]\n",
    "    \n",
    "        anomaly_range_start = np.where(x == anomaly_range[0])[0][0]\n",
    "        anomaly_range_end = np.where(x == anomaly_range[-1])[0][0]\n",
    "\n",
    "        num_points_in_anomaly_range = np.sum(anomaly_indexes[START:END])\n",
    "        predicted_anomalies = [\n",
    "            y_pred[:, signal][START:END][i] > upper_pi[START:END][i] or \n",
    "            y_pred[:, signal][START:END][i] < lower_pi[START:END][i] for i in range(0, END - START)\n",
    "        ]\n",
    "        \n",
    "        in_range_anomalies = predicted_anomalies[anomaly_range_start:anomaly_range_end]\n",
    "    \n",
    "        positions = [111]\n",
    "        fig = plt.figure(figsize=(16, 8))\n",
    "        axs = [fig.add_subplot(i) for i in positions]\n",
    "\n",
    "        axs[0].plot(x, lower_pi[START:END], linestyle='--', label = \"Lower Bound\")\n",
    "        axs[0].plot(x, upper_pi[START:END], linestyle='--', label = \"Upper Bound\")\n",
    "        axs[0].plot(x, y_pred[:, signal][START:END], label = \"Actual\", color=\"#bdbdbd\")\n",
    "        axs[0].plot(x, y_hat[:, signal][START:END], label = \"Predicted\", color=\"#252525\")\n",
    "        axs[0].set_ylim(-10, 10)\n",
    "        red_marks = x[predicted_anomalies]    \n",
    "        [axs[0].axvspan(red_marks[i], red_marks[i], alpha=0.1, lw=5, color='red') for i in range(0, len(red_marks) - 1)]\n",
    "    \n",
    "\n",
    "        [ax.legend() for ax in axs]\n",
    "\n",
    "        if verbose:\n",
    "            print(\\\n",
    "                'Total number of points in anomaly range: {num_points_in_anomaly_range} \\n Total number of flagged anomalies:  {num_flagged} \\n In range anomalies: {in_range_anomalies} \\n Out of range anomalies: {out_of_range_anomalies}'.format(\n",
    "                    num_points_in_anomaly_range = num_points_in_anomaly_range,\n",
    "                    num_flagged = np.sum(predicted_anomalies),\n",
    "                    in_range_anomalies = np.sum(in_range_anomalies),\n",
    "                    out_of_range_anomalies = np.sum(predicted_anomalies) - np.sum(in_range_anomalies)\n",
    "            ))\n",
    "\n",
    "pi_anomaly_detection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = plt.figure(figsize=(16,8))\n",
    "plt.plot(np.linspace(0, 1.0, 1000), np.log(1.0000000001 - np.linspace(0, 1.0, 1000)) / np.log(1.0 - 0.9999999999))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
